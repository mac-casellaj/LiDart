\documentclass[12pt, titlepage]{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{float}
\usepackage[left=1.65cm, right=2cm, top=2cm, bottom=2cm]{geometry}
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
%\usepackage[round]{natbib}

\input{../Comments}
\input{../Common}

\begin{document}

\title{System Verification and Validation Plan for \progname{}} 
\author{\authname}
\date{\today}
	
\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}p{4cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Authors} & {\bf Notes}\\
\midrule
02/Nov/2022 & 1.0 & Michaela Schnull \newline Jonathan Casella \newline Kareem Elmokattaf \newline Neeraj Ahluwalia & Initial Release\\
\bottomrule
\end{tabularx}

\newpage

\tableofcontents

\listoftables
\wss{Remove this section if it isn't needed}

\listoffigures
\wss{Remove this section if it isn't needed}

\newpage

\section{Symbols, Abbreviations and Acronyms}

\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l l} 
  \toprule		
  \textbf{symbol} & \textbf{description}\\
  \midrule 
  CAD & Computer Aided Design\\
  DRC & Design Rule Check\\
  ERC & Electrical Rule Check\\
  GUI & Graphical User Interface\\
  HA & Hazard Analysis\\
  LiDAR & Light Imaging, Detection, and Ranging\\
  MG & Module Guide\\
  MIS & Module Interface Specification\\
  SLAM & Simultaneous Localization and Mapping\\
  SRS & System Requirements Specification\\
  V\&V & Verification and Validation\\
  T & Test\\
  TA & Teaching Assistant\\
  \bottomrule
\end{tabular}\\

\wss{symbols, abbreviations or acronyms --- you can simply reference the SRS
  \cite{SRS} tables, if appropriate}

\wss{Remove this section if it isn't needed}

\newpage

\pagenumbering{arabic}
\wss{provide an introductory blurb and roadmap of the Verification and Validation plan}
  
This document presents a verification and validation plan for the \progname~ system. It will be used to establish verification and testing procedures and create a plan to determine if \progname~ meets it's goals as defined in the Problem Statement and Goals document.\\
\newline
\noindent The remainder of this document is structured as follows:

\begin{itemize}
  \item \textbf{Section \ref{GeneralInfo}} provides background information about the ~\progname system which will be subject to verification and validation activities. It also outlines the objectives of this plan and lists relevant documents.
  \item \textbf{Section \ref{Plan}} defines the verification and validation team roles and responsibilities. It presents verification methodologies and tools that will be used.
  \item \textbf{Sections \ref{SysTests}} and \textbf{\ref{UnitTests}} define what will be tested, and provide specific test cases. Furthermore, traceability matrices are provided to link test cases to requirements.
\end{itemize}

\section{General Information} \label{GeneralInfo}

\subsection{Summary}

\wss{Say what software is being tested.  Give its name and a brief overview of
  its general functions.}
  
  \progname~ is a low cost, simple to use, 3D scanning robot. The \progname~ system uses of low cost LiDAR sensors, consumer grade web cams, and inexpensive location markers. The user interfaces with the robot through GUI that allows them to remotely drive the robot and perform 3D scans.

\subsection{Objectives}

\wss{State what is intended to be accomplished.  The objective will be around
  the qualities that are most important for your project.  You might have
  something like: ``build confidence in the software correctness,''
  ``demonstrate adequate usability.'' etc.  You won't list all of the qualities,
  just those that are most important.}
  
The purpose of this document is to create a plan to demonstrate that \progname~ satisfies requirements as specified in the SRS and meets the goals of the project. This includes following objectives:
  
\begin{itemize}
  \item Validate that the \progname~ system meets its goals
  \item Create a plan to asses if the \progname~ system is in conformance with both functional and non-functional requirements as specified in the SRS
  \item Identify the methodologies, tools, and equipment that will be used to perform V\&V activities
  \item Create test cases to execute the V\&V plan
\end{itemize}

\subsection{Relevant Documentation}

\wss{Reference relevant documentation.  This will definitely include your SRS
  and your other project documents (design documents, like MG, MIS, etc).  You
  can include these even before they are written, since by the time the project
  is done, they will be written.}
  
Project documentation such as the SRS and design documents are referred to throughout the V\&V plan. Relevant documents are included below for reference.

\begin{itemize}
	\item System Requirements Specification (SRS) \cite{SRS}
	\item Problem Statement and Goals \cite{PSG}
	\item Module Interface Specification (MIS) \cite{MIS}
	\item Module Guide (MG) \cite{MG}
	\item Hazard Analysis (HA) \cite{FMEA}
\end{itemize}

\section{Plan} \label{Plan}

\wss{Introduce this section.   You can provide a roadmap of the sections to
  come.}

This section introduces methods and techniques used to verify design requirements and provides a high-level plan to validate the \progname~ system. 

\subsection{Verification and Validation Team}

\wss{Your teammates.  Maybe your supervisor.
  You should do more than list names.  You should say what each person's role is
  for the project's verification.  A table is a good way to summarize this information.}
  
\noindent Table \ref{Table:Roles} summarizes the roles and responsibilities of the verification and validation team.
  
\begin{table}[H]
\caption{Team Member Roles}
\label{Table:Roles}
\begin{tabularx}{\textwidth}{|p{5cm}|X|}
\hline{\bf Team Member} & {\bf Roles and Responsibilities} \\
\hline
Jonathan Casella & - Software testing lead\newline - Implementation of automated software testing methods\newline - Design review lead\\
\hline
Michaela Schnull &  - Verification of project documents including the SRS and V\&V plan \newline - Reporting of verification and validation activities \newline - Printed circuit board verification\\
\hline
Kareem Elmokattaf &  - Responsible for the design and execution of testing procedures \newline - Maintenance of  records documenting results from testing activities \newline - Code verification\\
\hline
Neeraj Ahluwalia &  - Preparation and maintenance of testing equipment \newline - Hardware verification\\
\hline
Independent Reviewers (i.e. Teaching Assistant) &  - Quality assurance and independent review\\
\hline
\end{tabularx}
\label{Table:Roles}
\end{table}

\subsection{SRS Verification Plan}

\wss{List any approaches you intend to use for SRS verification.  This may include
  ad hoc feedback from reviewers, like your classmates, or you may plan for 
  something more rigorous/systematic.}

\wss{Maybe create an SRS checklist?}

The SRS will be verified to ensure that requirements are complete, unambiguous, and meet the goals of the \progname~ system. The following methods shall be used to verify the SRS: 

\begin{itemize}
  \item Verify that the SRS follows the SRS checklist \cite{Checklist-SRS}
  \item Review from all team members using GitHub pull request reviews
  \item Independent review from the TA and classmates
\end{itemize}

\subsection{Design Verification Plan}

\wss{Plans for design verification}

\wss{The review will include reviews by your classmates}

\wss{Create a checklists?}
The design of the \progname~ system will be verified throughout development to ensure the system meets specifications and functions as intended. The following methods shall be used to verify the design:

\begin{itemize}
  \item Hold internal design reviews before the proof of concept demo and prior to manufacturing of the system for Revision 0 and Revision 1 project phases
  \item Perform a failure modes and effects analysis
  \item Independent review from teaching assistants and classmates
  \item Verify that the design documentation follows the MIS \cite{Checklist-MIS} and MG \cite{checklist-MG} checklists
\end{itemize}

\subsection{Verification and Validation Plan Verification Plan}

\wss{The verification and validation plan is an artifact that should also be verified.}

\wss{The review will include reviews by your classmates}

\wss{Create a checklists?}

The V\&V plan will be verified to ensure that the plan to verify and validate the \progname~ system is complete and feasible. The following methods shall be used to verify the V\&V plan:

\begin{itemize}
  \item Independent review from the TA and classmates
  \item Review from all team members using GitHub pull request reviews
    \item Verify that the V\&V plan follows the V\&V plan checklist \cite{Checklist-VnV}
\end{itemize}

\subsection{Implementation Verification Plan}

\wss{You should at least point to the tests listed in this document and the unit
  testing plan.}

\wss{In this section you would also give any details of any plans for static verification of
  the implementation.  Potential techniques include code walkthroughs, code
  inspection, static analyzers, etc.}
  
  The implementation verification plan will be used to ensure the \progname~ system meets all requirements as specified in the SRS. Verification methods that will be used include review, analysis, demonstration, and testing. 
\begin{itemize}
  \item \textbf{Review}: Review can be used when meeting a requirement is evident to a trained observer. Review of engineering drawings, code, or the physical device may be used. Techniques include code walk-throughs, code inspection, and drawing reviews.
  \item \textbf{Analysis}: Analysis can be used to verify design requirements where physical testing is not necessary, for example through mathematical and computer modeling. Analysis of data obtained through testing may be used to verify requirements. This verification method must be conducted by qualified individuals.
  \item \textbf{Demonstration}: Demonstration can be used to show that the system functions as intended. Unlike testing, demonstration does not require further analysis to determine if the system meets a requirement.
  \item \textbf{Testing}: Testing can be used to verify the behaviour of the system. Testing is conducted in a controlled environment with defined inputs and outputs. Test results must be analyzed to determine if tests pass or fail. Techniques that will be used include unit testing, automated testing, regression testing, and integration testing.
\end{itemize}

\noindent Section~\ref{SysTests} specifies system test cases and Section~\ref{UnitTests} specifies unit test cases.

\subsection{Automated Testing and Verification Tools}

\wss{What tools are you using for automated testing.  Likely a unit testing
  framework and maybe a profiling tool, like ValGrind.  Other possible tools
  include a static analyzer, make, continuous integration tools, test coverage
  tools, etc.  Explain your plans for summarizing code coverage metrics.
  Linters are another important class of tools.  For the programming language
  you select, you should look at the available linters.  There may also be tools
  that verify that coding standards have been respected, like flake9 for
  Python.}

\wss{If you have already done this in the development plan, you can point to
that document.}

\wss{The details of this section will likely evolve as you get closer to the
  implementation.}

\subsubsection{Rust}
Software for the LiDart project will be written in Rust, which natively includes testing facilities.
The testing facilities built into Rust are explained in chapter 5 of the
rustc book \cite{rust}.

\subsubsection{Rustfmt}
The primary linter for Rust is Rustfmt. Rustfmt will be used to ensure a consistent
programming style across all contributors.

\subsubsection{Autodesk Inventor}
LiDart's CAD suite of choice, Autodesk Inventor, will be used to ensure no mechanical conflicts
exist in the design prior to manufacturing and assembly. This will be done by first modeling the LiDart
robot in Autodesk Inventor then using tools within Inventor to detect any
collisions or interpenetrating components.

\subsubsection{EAGLE}
Printed circuit board design will be done in EAGLE, which has built-in error checking tools. ERC (Electrical Rule Check) will be used to test schematics for electrical errors. DRC (Design Rule Check) will be used to ensure there are no board layout errors.

\subsection{System Validation Plan}

\wss{If there is any external data that can be used for validation, you should
  point to it here.  If there are no plans for validation, you should state that
  here.}

\wss{You might want to use review sessions with the stakeholder to check that
the requirements document captures the right requirements.  Maybe task based
inspection?}

\wss{This section might reference back to the SRS verification section.}

% \subsubsection{Point Cloud Stitching}
% Generate a set of simulated measurements along with the expected resulting
% point cloud. These simulated measurements can then be provided to the
% point cloud stitching subsystem and the result point cloud can be compared against
% the expected value.  

% \subsubsection{Landmark Extraction}
% Assemble a set of validation images and associated landmark data,
% these images can be used to ensure that the landmark extraction subsystem
% is producing the correct results.

% \subsubsection{State Estimation}
% Generate a set of simulated landmark measurements along with the correct state
% at that time. These simulated measurements can then be provided to the
% state estimation subsystem and the estimated state can be compared against
% the correct state at that time.  

% \subsubsection{Movement Controller}
% Write test scenarios that specify the expected output for a given input,
% these scenarios should cover ???

This section lays out a series of validation exercises that will be performed before the system is deemed
suitable for general users. The following exercises are designed to test the 3 major goals set out
in the problem statement.

\subsubsection{Accurate 3D Scanning}

To validate the accuracy of the 3D scans a test environment will be constructed and
scanned. Said test environment will have objects with known shapes at predetermined positions.
The resulting 3D scan will be compared against the expected values for the test environment.
If the point cloud matches the expected result within some tolerance this validation exercise will
be deemed complete. 

\subsubsection{Low Cost Hardware}

To validate that the goal of low cost, easily accessable hardware was met two exercises will be performed. 
\ \\

\noindent The first exercise will be to compare LiDart's price to other options in the market with equivalent features
and comparable build quality. LiDart's price should fall below the median price of the existing solutions.
\ \\

\noindent The second exercise will be to evaluate the accessibility of the hardware used by LiDart. During
this exercise a list of alternative hardware components will be created for all major components of the LiDart
system (e.g. motor controller, motors, cameras). This exercise will be deemed complete when all major components
have at least one alternate part listed.

\subsubsection{Ease of Use}

To validate LiDart's ease of use a focus group will be used. The focus group will consist of
subjects with no prior knowledge of the system. Each member of the focus group will be provided
with the user manual then asked to scan an object. The time required to complete the scan and the 
percentage of successful subjects will be used to determine the success of this exercise.
\ \\

\noindent \textbf{Usability survey questions}

\section{System Test Description} \label{SysTests}
	
\subsection{Tests for Functional Requirements}

\wss{Subsets of the tests may be in related, so this section is divided into
  different areas.  If there are no identifiable subsets for the tests, this
  level of document structure can be removed.}

\wss{Include a blurb here to explain why the subsections below
  cover the requirements.  References to the SRS would be good here.}

% \subsubsection{Area of Testing1}

\wss{It would be nice to have a blurb here to explain why the subsections below
  cover the requirements.  References to the SRS would be good here.  If a section
  covers tests for input constraints, you should reference the data constraints
  table in the SRS.}
		

\begin{enumerate}


\item{R1T\\}

Verification Method: Testing	\\	
Initial State: Nothing has been sent to the robot to output \\
Input: Arrow key movement (example: right arrow key) \\ 
Output: Robot moves in the direction specified (example: to the right) \\ 
How test will be performed: The robot will be given a series of inputs from the keyboard such as Right,Left and forward. The robot will then be observed and make sure that it follows the motions specified. This will verify that the robot is taking the input from the user as specified \\
\item{R2T\\}

Verification Method: Testing	\\	
Initial State: Robot is operating normally \\ 
Input: Emergency stop button is pressed \\ 
Output: Robot should completely shut down \\
How test will be performed: Inputs will be sent to the robot and the robot should not action any of them. So the inputs can be movement (left, right and forward) or it can be to scan the object.  \\
\item{R3T\\}

Verification Method: Testing	\\	
Initial State: Robot is stationary \\
Input: From the control, there will be input specified to move the robot forward, backwards, left and right \\
Output: Robot should move in all specified directions \\
How test will be performed: Inputs will be sent to the robot and the robot should operate accordingly. The robot should move forward, backward, and rotate left and right. \\
\item{R4T\\}

Verification Method: Testing	\\
Initial state: Robot is stationary \\
Input: No inputs are given to the robot \\
Output: Robot does not move or do any functions \\
How test will be performed: Robot will be left without any inputs given to it and its behaviour will be monitored/observed \\
\item{R5T\\}

Verification Method: Testing	\\
Initial state: Robot is stationary \\
Input: Through a remote device connected over the internet, there will be commands given to the robot (example: Move left and Scan) \\
Output: Robot should move left and then start scanning  \\
How test will be performed: Robot will be remotely connnected to a control source and the robot will then be given commands from the control source and the actions of the robot will be observed \\
\item{R6T\\}

Verification Method: Testing	\\
Initial state: Robot will be idle (TO BE REVIEWED) \\
Input: Through the internet connection established, parameters will be sent to the robot (example: robot status) \\
Output: Robot will respond over wifi connection with the robot status  \\
How test will be performed: Over a wifi connection a control will send certain paramters to the robot and the expected output should be recieved from the robot \\
\item{R7T\\}

Verification Method: Testing	\\
Initial state: Robot is currently operating \\
Input: Robot switch will be flicked to go from "On" to "Off"\\
Output: Robot should power down and not have any power \\
How test will be performed: Robot will be powered on working. After confirming that the robot is powered on and performing actions, the robot's switch will be flicked to off and the robot should turn off \\
\item{R8T\\}

Verification Method: Testing	\\
Initial state: Robot battery is low \\
Input: Robot batter will be connected to a battery charger \\
Output: Robot battery percentage should start increasing \\
How test will be performed: Robot will have a low battery. The battery will then be connected to a charger and tester will observe as the battery percentage increases on the GUI.\\
\item{R9T\\}

Verification Method: Testing	\\
Initial state: Robot is operating without having scanned anything \\
Input: Robot scan\\
Output: Output from the robot to the remote connection will be the scans coming from the LiDAR senso\\
How test will be performed: Robot will be placed close to an object and instructed to scan the object. The tester will then observer the output from the robot on the remote connection. \\
\item{R10T\\}

Verification Method: Testing	\\
Initial state: Robot uncalibrated \\
Input: Landmarks in the surrounding and the instruction to clibrate the position of the robot \\
Output: Coordinate of the robot in comparison to the landmarks\\
How test will be performed: Landmarks will be placed a specific distance away from the robot at a specific orientation. The robot will be asked to calibrate. The tester will verify the measurements from the robot and verify that they are correct \\
\item{R11T\\}

Verification Method: Testing	\\
Initial state: Robot has scanned an object \\
Input: User identifes that they are done scanning and what to see the results \\
Output: Robot will send the output file to the remote connection  \\
How test will be performed: (TO BE REVIEWED) Robot will have files preinstalled and then asked to communicate them in the same that they will communicate the results of the scan. Those files will the be verified to be correct and uncorrupted \\
\item{R12T\\}

Verification Method: Testing	\\
Initial state: Robot moving with the camera installed \\
Input: User moving the robot around \\
Output: Live feed from the camera onto the remote connection \\
How test will be performed: Tester will place different objects infront of the robot and watch them change on the live feed on the GUI\\
\item{R13T\\}

Verification Method: Testing	\\
Initial state: Robot scanning the object\\
Input: User continuing the scan of an object \\
Output: Current information on the scan. The current 3D scan model of the scan\\
How test will be performed: Tester will observe as the scan is happening and look at the output on the GUI from the robot. The tester will be able to confirm that the scan is coming as the robot is scanning\\
\item{R14T\\}

Verification Method: Testing	\\
Initial state: Robot is ready to scan\\
Input: User asking for the current state of the robot\\
Output: Robot outputs that it is ready to scan\\
How test will be performed: Robot will be put in different states (Idle, ready to scan, etc..) and then asked to output the state to the GUI. The tester will be able to confirm that the output is matching what is expected \\



\end{enumerate}

\subsection{Tests for Nonfunctional Requirements}

\wss{The nonfunctional requirements for accuracy will likely just reference the
  appropriate functional tests from above.  The test cases should mention
  reporting the relative error for these tests.  Not all projects will
  necessarily have nonfunctional requirements related to accuracy}

\wss{Tests related to usability could include conducting a usability test and
  survey.  The survey will be in the Appendix.}

\wss{Static tests, review, inspections, and walkthroughs, will not follow the
format for the tests given below.}

\subsubsection{Usability Testing}
		
\paragraph{Title for Test}

\begin{enumerate}

\item{NFR1\\}

Verification Method: Testing	\\				
Initial State: Robot is fully assembled	\\			
Input: n/a\\
Output: The 3D scan must be within SCAN\_TOL \\
How test will be performed: The object that was scanned will be measured. The measurements from the object will be compared to that of the 3D scan provided by the robot S\\
  
\item{NFR2\\}

Verification Method: Testing	\\				
Initial State: Robot is fully assembled and is operating	\\			
Input: n/a\\
Output: The robot is moving at a speed of ROBOT\_SPEED \\
How test will be performed: The robot will have to cover a specified distance. The time it takes to cover that distance will be measured. The speed can thus be calculated to determine the speed of the robot \\
  
\item{NFR3\\}

Verification Method: Testing	\\				
Initial State: Robot is fully assembled and operating	\\			
Input: n/a\\
Output: Robot must run for RUN\_TIME \\
How test will be performed: The robot will be fully charged, and then left to operate. The time from when it is turned on till the battery runs out will be measured \\
			

\item{NFR4\\}

Verification Method: Testing	\\				
Initial State: Robot is fully assembled	and operating\\			
Input: n/a\\
Output: The system must be able to produce a 3D scan within SCANNING\_TIME \\
How test will be performed: Once the robot starts scanning, the timer will be started until the single planar scan is completed. When it is completed the timer will be stopped \\

\item{NFR5\\}

Verification Method: Testing	\\				
Initial State: Robot is fully assembled and operating	\\			
Input: n/a\\
Output: The system must be able to output the final 3D scan withing MA\_PROCESS\_T time \\
How test will be performed: Once the robot starts scanning the object, the timer will be started. Once the robot is fully done scanning and has produced the 3D scan file, the timer will be stopped \\

\item{NFR6\\}

(*TO BE CHECKED*)
Verification Method: Testing	\\				
Initial State: Robot is fully assembled	and operating\\			
Input: n/a\\
Output: The robot must respond within MAX\_RESP\_T amount of time \\
How test will be performed: A command will be sent to the robot at a specified time, the robot will respond with the time time. The time difference will be the response time \\

\item{NFR7\\}

(*TO BE CHECKED*)
Verification Method: Testing	\\				
Initial State: Robot is fully assembled	\\			
Input: n/a\\
Output: The live feed of the video must have a minimum resolution of  MIN\_VIDEO\_RES \\
How test will be performed: The live feed from the robot can be stored on a Windows platform. The video can then be checked from its properties to verify the resolution \\

\item{NFR8\\}

(*TO BE CHECKED*)
Verification Method: Testing	\\				
Initial State: Robot is fully assembled	and operating\\			
Input: n/a\\
Output: The live feed displayed on the GUI must have a maximum delay of MAX\_VIDEO\_DELAY \\
How test will be performed: NO IDEA HOW THIS ONE IS TO BE DONE. CLOCK? MOVE SOMETHING AWAY FROM DISPLAY? IDK

\item{NFR10\\}

Verification Method: Testing	\\				
Initial State: Robot is fully assembled	\\			
Input: n/a\\
Output: The robot must weight less than ROBOT\_MAX\_WEIGHT\\
How test will be performed: The robot shall be weighed on a scale. The weight of the robot and the accuracy of the measuring device must be recorded.\\

\item{NFR11\\}

Verification Method: Testing\\					
Initial State: Robot is fully assembled	\\			
Input: n/a\\
Output: The robot dimensions must be less than ROBOT\_MAX\_DIM \\
How test will be performed: The robot dimensions (length x width x height) shall be measured with a measuring tape. The robot dimensions and the accuracy of the measuring device must be recorded.\\

\item{NFR12\\}

Verification Method: Review\\					
Initial State: The GUI main page is open\\			
Input: n/a\\
Output: n/a\\
How test will be performed: Each page will be navigated to from the main screen. The number of navigation levels will be recorded for each page. It must take less than MAX\_NUM\_LEVELS to navigate to any page on the application\\

\item{NFR13\\}

Verification Method: Review\\					
Initial State: The GUI main page is open\\			
Input: n/a\\
Output: n/a\\
How test will be performed: A qualified individual will review the website to ensure all text is consistent, has a minimum font size of MIN\_FONT\_SIZE, and is sans-serif. \\

\item{NFR9\\}

Verification Method: Testing\\					
Initial State: The robot is powered-on and connected to the GUI through WiFi\\			
Input: Module Guide document\\
Output: At least 9/10 users with no prior knowledge of the system are able to successfully drive the robot, perform a scan, and save the scan data\\
How test will be performed: A usability test shall be performed. Users will be given the Module Guide and instructed to drive the robot, perform a scan, and save the scanned data.
user manual.\\ 

\item{NFR14, NFR12, NFR9\\}

Verification Method: Usability Survey\\					
Initial State: 		\\
Input: \\
Output: \\
How test will be performed:\\

\item{NFR15\\}

Verification Method: Testing\\					
Initial State: 	The robot is powered-on and connected to the GUI through WiFi	\\
Input: User begins scanning and then attempts to move the robot\\
Output: Error message stating the robot cannot move until scanning is complete\\
How test will be performed:

\item{NFR20, NFR21\\}

Verification Method: Testing\\					
Initial State:  The GUI application is installed\\ 
Input: Open the application\\
Output: The application must run without crashing or performance issues\\
How test will be performed: The application will run on a computer with the specifications IntelCore i5 processor and 8 GB of RAM or equivalent.\\

\item{NFR22\\}

Verification Method: Review\\					
Initial State:  The robot is fully assembled\\
Input: n/a\\
Output: n/a\\
How test will be performed: A qualified individual shall inspect the robot to ensure there is no exposed wiring.\\


\item{NFR25\\}

Verification Method: Review\\					
Initial State:  The robot is fully assembled\\
Input: n/a\\
Output: n/a\\
How test will be performed: A qualified individual shall inspect the robot to ensure it is in conformance with CSA 22.1:21 (Canadian Electrical Code) \cite{CSA1} and CSA Z434 (Industrial robots and robot systems) \cite{CSA2}\\

\end{enumerate}


\subsection{Traceability Between Test Cases and Requirements}
\begin{table}[H]
  \centering
  \caption{Requirements Dependency Matrix}
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
  \hline
    & RT1 & RT2 & RT3 & RT4 & RT5 & RT6 & RT7 & RT8 & RT9 & RT10 & RT11 & RT12 & RT 13 & RT14\\
  \hline
  R1      &X & & & & & & & & & & & & & \\ 
  \hline
  R2      & &X & & & & & & & & & & & & \\ 
  \hline
  R3      &X & &X & & & & & & & & & & & \\ 
  \hline
  R4      & & & &X & & & & & & & & & & \\ 
  \hline
  R5      &X & & & &X &X & & & & & & & & \\ 
  \hline
  R6      & & & & &X &X & & & & & & & & \\ 
  \hline
  R7      & & & & & & &X & & & & & & & \\ 
  \hline
  R8      & & & & & & & &X & & & & & & \\ 
  \hline
  R9      & & & & & & & & &X & & & & & \\ 
  \hline
  R10      & & & & & & & & & &X & & & & \\ 
  \hline
  R11      & & & & & & & & & & &X & & & \\ 
  \hline
  R12      & & & & & & & & & & & &X & & \\ 
  \hline
  R13      & & & & & & & & & & & & &X & \\ 
  \hline
  R14      & & & & & & & & & & & & & &X \\ 
  \hline
  \end{tabular}
  
  \label{Table:A_trace}
  \end{table}

\wss{Provide a table that shows which test cases are supporting which
  requirements.}

\section{Unit Test Description} \label{UnitTests}

\wss{Reference your MIS (detailed design document) and explain your overall
  philosophy for test case selection.}  
\wss{This section should not be filled in until after the MIS (detailed design
  document) has been completed.}

\subsection{Unit Testing Scope}

\wss{What modules are outside of the scope.  If there are modules that are
  developed by someone else, then you would say here if you aren't planning on
  verifying them.  There may also be modules that are part of your software, but
  have a lower priority for verification than others.  If this is the case,
  explain your rationale for the ranking of module importance.}

\subsection{Tests for Functional Requirements}

\wss{Most of the verification will be through automated unit testing.  If
  appropriate specific modules can be verified by a non-testing based
  technique.  That can also be documented in this section.}

\subsubsection{Module 1}

\wss{Include a blurb here to explain why the subsections below cover the module.
  References to the MIS would be good.  You will want tests from a black box
  perspective and from a white box perspective.  Explain to the reader how the
  tests were selected.}

\begin{enumerate}

\item{test-id1\\}

Type: \wss{Functional, Dynamic, Manual, Automatic, Static etc. Most will
  be automatic}
					
Initial State: 
					
Input: 
					
Output: \wss{The expected result for the given inputs}

Test Case Derivation: \wss{Justify the expected value given in the Output field}

How test will be performed: 
					
\item{test-id2\\}

Type: \wss{Functional, Dynamic, Manual, Automatic, Static etc. Most will
  be automatic}
					
Initial State: 
					
Input: 
					
Output: \wss{The expected result for the given inputs}

Test Case Derivation: \wss{Justify the expected value given in the Output field}

How test will be performed: 

\item{...\\}
    
\end{enumerate}

\subsubsection{Module 2}

...

\subsection{Tests for Nonfunctional Requirements}

\wss{If there is a module that needs to be independently assessed for
  performance, those test cases can go here.  In some projects, planning for
  nonfunctional tests of units will not be that relevant.}

\wss{These tests may involve collecting performance data from previously
  mentioned functional tests.}

\subsubsection{Module ?}
		
\begin{enumerate}

\item{test-id1\\}

Type: \wss{Functional, Dynamic, Manual, Automatic, Static etc. Most will
  be automatic}
					
Initial State: 
					
Input/Condition: 
					
Output/Result: 
					
How test will be performed: 
					
\item{test-id2\\}

Type: Functional, Dynamic, Manual, Static etc.
					
Initial State: 
					
Input: 
					
Output: 
					
How test will be performed: 

\end{enumerate}

\subsubsection{Module ?}

...

\subsection{Traceability Between Test Cases and Modules}

\wss{Provide evidence that all of the modules have been considered.}
				
\newpage
\nocite{*}
\bibliographystyle{ieeetr}
\bibliography{references}

\newpage

\section{Appendix}

\subsection{Symbolic Parameters}

The definition of the test cases will call for SYMBOLIC\_CONSTANTS.
Their values are defined in this section for easy maintenance.

\subsection{Usability Survey Questions?}

\wss{This is a section that would be appropriate for some projects.}

\newpage{}
\section*{Appendix --- Reflection}

The information in this section will be used to evaluate the team members on the
graduate attribute of Lifelong Learning.  Please answer the following questions:

\begin{enumerate}
  \item What knowledge and skills will the team collectively need to acquire to
  successfully complete the verification and validation of your project?
  Examples of possible knowledge and skills include dynamic testing knowledge,
  static testing knowledge, specific tool usage etc.  You should look to
  identify at least one item for each team member.
  \item For each of the knowledge areas and skills identified in the previous
  question, what are at least two approaches to acquiring the knowledge or
  mastering the skill?  Of the identified approaches, which will each team
  member pursue, and why did they make this choice?
\end{enumerate}

\end{document}